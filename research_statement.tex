%!TEX TS-program = xelatex
%!TEX encoding = UTF-8 Unicode
% Awesome CV LaTeX Template for Cover Letter
%
% This template has been downloaded from:
% https://github.com/posquit0/Awesome-CV
%
% Authors:
% Claud D. Park <posquit0.bj@gmail.com>
% Lars Richter <mail@ayeks.de>
%
% Template license:
% CC BY-SA 4.0 (https://creativecommons.org/licenses/by-sa/4.0/)
%


%-------------------------------------------------------------------------------
% CONFIGURATIONS
%-------------------------------------------------------------------------------
% A4 paper size by default, use 'letterpaper' for US letter
\documentclass[11pt, a4paper]{awesome-cv}

% Configure page margins with geometry
\geometry{left=1.4cm, top=.8cm, right=1.4cm, bottom=1.8cm, footskip=.5cm}

% Color for highlights
% Awesome Colors: awesome-emerald, awesome-skyblue, awesome-red, awesome-pink, awesome-orange
%                 awesome-nephritis, awesome-concrete, awesome-darknight
\colorlet{awesome}{awesome-skyblue}
% Uncomment if you would like to specify your own color
% \definecolor{awesome}{HTML}{CA63A8}

% Colors for text
% Uncomment if you would like to specify your own color
% \definecolor{darktext}{HTML}{414141}
% \definecolor{text}{HTML}{333333}
% \definecolor{graytext}{HTML}{5D5D5D}
% \definecolor{lighttext}{HTML}{999999}
% \definecolor{sectiondivider}{HTML}{5D5D5D}

% Set false if you don't want to highlight section with awesome color
\setbool{acvSectionColorHighlight}{true}

% If you would like to change the social information separator from a pipe (|) to something else
\renewcommand{\acvHeaderSocialSep}{\quad\textbar\quad}


%-------------------------------------------------------------------------------
%	PERSONAL INFORMATION
%	Comment any of the lines below if they are not required
%-------------------------------------------------------------------------------
% Available options: circle|rectangle,edge/noedge,left/right
% \photo[circle,noedge,left]{./examples/profile}
\name{Ricardo}{Barrué}
\position{PhD researcher at \href{https://www.lip.pt/}{Laboratório de Instrumentação e Física Experimental de Partículas (LIP)} and \href{https://tecnico.ulisboa.pt/en/}{Instituto Superior Técnico (IST)}}
\address{LIP: Av. Prof. Gama Pinto, n.2, 1649-003 Lisboa, Portugal; IST: Av. Rovisco Pais, 1, 1049-001 Lisboa, Portugal}

\email{ricardo.barrue@cern.ch}
%\dateofbirth{January 1st, 1970}
% \homepage{www.posquit0.com}
\github{rbarrue}
\linkedin{ricardo-barrue}
\gitlab{rcoelhob}
\orcid{0000-0001-8985-5379}
% \gitlab{gitlab-id}
% \stackoverflow{SO-id}{SO-name}
% \twitter{@twit}
% \skype{skype-id}
% \reddit{reddit-id}
% \medium{madium-id}
% \kaggle{kaggle-id}
% \hackerrank{hackerrank-id}
% \googlescholar{googlescholar-id}{name-to-display}
%% \firstname and \lastname will be used
% \googlescholar{googlescholar-id}{}
% \extrainfo{extra information}

% \quote{``Be the change that you want to see in the world."}


%-------------------------------------------------------------------------------
%	LETTER INFORMATION
%	All of the below lines must be filled out
%-------------------------------------------------------------------------------
% The company being applied to
\recipient
  {Robert Schöfbeck}
  {HEPHY - Institute of High Energy Physics \\ Nikolsdorfer Gasse 18 \\ 1050 Wien, Austria} 
% The date on the letter, default is the date of compilation
\letterdate{\today}
% The title of the letter
\lettertitle{Research Statement}
% How the letter is opened
\letteropening{}
% How the letter is closed
\letterclosing{Kind regards}
% Any enclosures with the letter
% \letterenclosure[Attached]{Curriculum Vitae}


%-------------------------------------------------------------------------------
\begin{document}

% Print the header with above personal information
% Give optional argument to change alignment(C: center, L: left, R: right)
\makecvheader[R]

% Print the footer with 3 arguments(<left>, <center>, <right>)
% Leave any of these blank if they are not needed
\makecvfooter
  {\today}
  {Ricardo Barrué ~~~·~~~ Research statement}
  {}

% Print the title with above letter information
\makelettertitle

%-------------------------------------------------------------------------------
%	LETTER CONTENT
%-------------------------------------------------------------------------------
\begin{cvletter}

  My research work has focused on the precise measurement of the properties of the Higgs boson and the search for tiny deviations from the Standard Model expectation that could be a sign of new physics. As a member of the ATLAS Collaboration, I have gained extensive experience across the entire analysis pipeline. Additionally, I became an expert in the jet reconstruction performance and operation of the ATLAS trigger system. Simultaneously, I explored simulation-based inference methods to overcome limitations in histogram-based analyses and improve searches for the new physics. In this research statement, I describe my research expertise in more detail and outline the future direction I aim to explore at HEPHY, framed by the open opportunities of top quark measurements using energy correlators and their SM interpretation.

  \lettersection{Data Analysis and Machine Learning for Higgs boson measurements}
  
  During my masters, I contributed to the first ATLAS search of $V(\to \textrm{leptons})H(\to b\bar{b})$ in the high-momentum regime, where we expect higher sensitivity to new physics contributions. I optimized Higgs boson identification and event selection criteria and was awarded exceptional ATLAS authorship for this analysis. It is published on \href{https://doi.org/10.1016/j.physletb.2021.136204}{Physics Letters B 816 (2021) 136204}.
  
  During my PhD, I contributed to the combined precision measurement of $V(\to \textrm{leptons})H(\to b\bar{b}/c\bar{c})$. I contributed to background modelling, including the training of a machine-learning-based reweighting method to reduce uncertainties from finite sample statistics and also worked extensively on fine-tuning the statistical (fit) model. The analysis was published in \href{https://doi.org/10.1007/JHEP04(2025)075}{J. High Energ. Phys. 2025, 75 (2025)}, and my contributions were crucial for the precision of the final result.
  
  Building on the foundation of that analysis, I proposed and led ATLAS's first search for CP-violating EFT components in the HWW vertex in $W(\to \ell \nu)H(\to b\bar{b})$ production. I developed the complete analysis pipeline, from the choice of CP-sensitive observable, categorization and modeling studies, and the development of the statistical model. Additionally, I supervised a master's student working on this analysis, parametrizing (STXS) signal strengths in bins of the CP-sensitive observable as a function of the Wilson coefficient of the EFT operator responsible for CP violation in this interaction. The analysis was published in \href{https://atlas.web.cern.ch/Atlas/GROUPS/PHYSICS/PUBNOTES/ATL-PHYS-PUB-2025-022/}{ATL-PHYS-PUB-2025-022}, containing the world's best constraints on the relevant Wilson coefficient.
  
  \lettersection{Neural Simulation-based Inference for searches of new physics in the Higgs sector}
  
  Analyses such as the ones mentioned above use frequentist likelihood-based inference procedures. Given that the full likelihood is intractable, they estimate the likelihood from histograms of a few variables, leading to suboptimal results. During my PhD, I explored neural simulation-based (likelihood-free) inference methods to overcome this limitation. These use information from event generators and neural networks with a large set of input variables, to estimate per-event quantities relevant for statistical inference with minimal loss of sensitivity.
  
  To improve searches for CP violation in Higgs boson interactions, I explored a neural simulation-based inference method that estimates sufficient statistics of the likelihood (score). This work, published in \href{https://doi.org/10.1007/JHEP04(2024)014}{J. High Energ. Phys. 2024, 14 (2024)} (of which I was the primary author) showed that such a method has performance competitive with traditional histogram-based approaches while being robust to the presence of backgrounds and (unobservable) neutrinos in the final state. I supervised a master's student on the extension of that work, exploring estimators of the likelihood ratio using parametrized neural networks, with explicit dependence on the value of relevant Wilson coefficients (numerator), using ensembles of neural networks for proper uncertainty quantification (paper in preparation).
  
  \lettersection{Future research directions}
  
  The top quark, in particular its mass, can be used as a probe of the consistency of the SM, from its contributions to low-energy observables measured with extreme precision, and due to the well defined loop-level relations with the mass of the W boson. Furthermore, its relation with the mass of the Higgs boson is related to the stability of the Universe. Thus, it is important to measure it as precisely as possible. The most precise measurement of the top mass comes from the statistical combination of ATLAS and CMS Run 1 measurements, with an uncertainty of 330 MeV.

  Very high momentum (boosted) hadronically decaying top quarks can be used to perform direct measurements of the mass of the top quark. Recent phenomenological work, published in \href{https://doi.org/10.1007/JHEP04(2025)072}{J. High Energ. Phys. 2025, 72 (2025)}, demonstrated that a class of large-radius jet substructure observables called energy correlators can be used to perform a precision measurement of the top quark mass, robust against many different experimental and theoretical uncertainties. Additionally, it points directions for future theoretical improvement to further improve the precision of such an extraction.

  My goal for this position is to implement a full experimental measurement of the relevant energy correlators at hadron-level, such that it can be directly compared to theoretical predictions. For this, I want to research and use per-event/unbinned unfolding techniques that can take into account the large set of experimental uncertainties commonly used. Such techniques, e.g. Unbinned Profile Unfolding, are becoming increasingly integrated into common HEP frameworks, as described in \href{https://arxiv.org/abs/2503.09720}{arXiv:2503.09720}. In parallel, I also want to explore methods to make the (per-event) hadron-level measurements available for use by theorists in a consistent way, such that increasingly precise measurements of the top quark mass can be done from the output of this analysis, as improvements in the theoretical calculations become available.

  % The High-Luminosity LHC will bring the largest dataset ever collected in the history of particle physics, which will allow probing phenomena with unprecedented precision and vastly increase the sensitivity to very rare processes. At the same time, it will also bring remarkable challenges to the optimal exploitation of its output: events will become more complex (with up to 200 simultaneous collisions), and data rates will increase by almost an order of magnitude. Drawing from my experience, I propose three key research directions that address HL-LHC challenges and align with DESY's priorities:
  
  % \textbf{Precision SM Measurements as a Window for BSM Physics}\\
  % No direct signs of physics beyond the Standard Model have been found so far, and it is unfeasible for experimentalists to properly explore the extremely large space of new physics models. My goal is to continue working on precision measurements of SM processes and explore techniques such as multi-dimensional unbinned unfolding (e.g. \href{https://arxiv.org/abs/2409.10421}{arXiv:2409.10421}). Such techniques can vastly increase the potential usability of the measurements by theorists, which can interpret the results in terms of many different new physics models, or in terms of bottom-up theories such as the Standard Model Effective Field Theory.

  % \textbf{Advancing Neural Simulation-Based Inference}\\
  % As we move toward precision measurements at the HL-LHC, I want to extend my work on neural simulation-based inference (SBI) methods by exploring more powerful architectures using low-level variables as input. Additionally, I also want to explore techniques to mitigate the significant computational requirements of these methods, such as `mining gold' (\href{https://arxiv.org/abs/1907.10621}{arXiv:1907.10621}), and implement such techniques in common experimental analysis tools. This will allow large improvements in the precision of many different analyses.
  
  % \textbf{Machine Learning and Software for Trigger and Data Acquisition Systems}\\
  % Low-latency machine-learning algorithms are starting to show potential to be used in the trigger systems of experiments. I want to work in the implementation of such algorithms, in particular for use in the first level of triggers, which require microsecond-level latencies. Additionally, I want to develop performant and robust software for the trigger and data acquisition infrastructure, in order to maximize the data-taking efficiency of the experiments, and thus their physics potential. My hands-on experience with trigger performance and trigger operations gives me a practical understanding of the constraints and challenges in implementing such solutions.

  The research directions above my ideas for this position. Nonetheless, throughout my research, I have demonstrated my ability to tackle complex challenges, learning quickly and adapting to evolving technical environments. I am enthusiastic about joining HEPHY's research environment, where I can contribute my experience and grow into new approaches for extracting the maximum out of top quark measurements.

\end{cvletter}

%-------------------------------------------------------------------------------
% Print the signature and enclosures with above letter information
\makeletterclosing

\end{document}